{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:07:23.472116Z",
     "start_time": "2025-04-25T18:07:18.564895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer , pipeline\n",
    "import torch"
   ],
   "id": "c8f8e7ee2d1e5791",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nima/Projects/persian_poetry generator/venvPPG/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:07:15.033980Z",
     "start_time": "2025-04-25T18:07:15.032447Z"
    }
   },
   "cell_type": "code",
   "source": "model_path = \"../gpt2-farsi-poetry\"",
   "id": "8e974972f8d40bb6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T18:07:30.875737Z",
     "start_time": "2025-04-25T18:07:28.944324Z"
    }
   },
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(42001, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=42001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:07:34.814453Z",
     "start_time": "2025-04-25T18:07:34.809521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_poem(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt=\"<START>\",\n",
    "    max_length=100,\n",
    "    num_return_sequences=1,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    device=None,\n",
    "    clean_output=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate Persian poems from a fine-tuned GPT-2 model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained GPT2LMHeadModel\n",
    "        tokenizer: Associated tokenizer\n",
    "        prompt (str): Starting prompt, usually \"<START>\"\n",
    "        max_length (int): Maximum length of the generated poem\n",
    "        num_return_sequences (int): Number of poems to generate\n",
    "        temperature (float): Sampling temperature (>1 = more randomness)\n",
    "        top_k (int): Top-K sampling\n",
    "        top_p (float): Top-P (nucleus) sampling\n",
    "        device (int or None): Device to use, e.g., 0 for GPU or None for auto\n",
    "        clean_output (bool): Replace <LINE_BREAK> and <END> in output\n",
    "\n",
    "    Returns:\n",
    "        List of generated poems as strings\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.convert_tokens_to_ids(\"<END>\")\n",
    "    )\n",
    "\n",
    "    poems = []\n",
    "    for output in output_sequences:\n",
    "        text = tokenizer.decode(output, skip_special_tokens=False)\n",
    "\n",
    "        if clean_output:\n",
    "            text = text.replace(\"<START>\", \"\")\n",
    "            text = text.replace(\"<END>\", \"\")\n",
    "            text = text.replace(\"<LINE_BREAK>\", \"\\n\")\n",
    "            text = text.replace(\"<PAD>\", \"\")\n",
    "            text = text.strip()\n",
    "\n",
    "        poems.append(text)\n",
    "\n",
    "    return poems if num_return_sequences > 1 else poems[0]\n"
   ],
   "id": "f1a06beed326887c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:07:45.253501Z",
     "start_time": "2025-04-25T18:07:43.891850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Robaee\n",
    "poem = generate_poem(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=\"<START><STYLE:ROBAEE>\",\n",
    "    max_length=80,\n",
    "    temperature=0.7,\n",
    "    top_k=70,\n",
    "    top_p=0.9\n",
    ")\n",
    "print(poem)\n"
   ],
   "id": "c14cb59abf9e2876",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<STYLE:ROBAEE>  دلدار چو می به ما میبخشد \n",
      " وز ما به ما هوای ما میبخشد \n",
      " ای دل تو را از ما چه میخواهی؟ \n",
      " ما را به تو جای ما میبخشد <|endoftext|>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:08:00.054665Z",
     "start_time": "2025-04-25T18:07:57.623510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ghazal\n",
    "ghazal = generate_poem(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=\"<START><STYLE:GHAZAL>\",\n",
    "    max_length=120,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "print(ghazal)"
   ],
   "id": "e305ce29018cb10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<STYLE:GHAZAL> بیا که تا مرا به تو باز آیم \n",
      " ز درد عشق تو چو جان فزای آیم \n",
      " ز درد عشق تو جانم به لب آمد \n",
      " ز درد عشق تو چون تو جان فزای آیم \n",
      " به هر که روی تو باشد از روی تو \n",
      " به چشم من به تو چون تو به جای آیم \n",
      " نه دل ز دست تو بر باد می رود \n",
      " نه صبر از دست تو بربای آیم\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:17:36.920011Z",
     "start_time": "2025-04-25T18:17:33.979389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Masnavi\n",
    "masnavi = generate_poem(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=\"<START><STYLE:MASNAVI>\",\n",
    "    max_length=140,\n",
    "    temperature=0.8,\n",
    "    top_k=70,\n",
    "    top_p=0.95\n",
    ")\n",
    "print(masnavi)"
   ],
   "id": "a79ed3be5885e96c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<STYLE:MASNAVI>  تو ای شاه، مکن دعوی شاهی \n",
      " که پادشاهی طلبد، تو شاهی \n",
      " غلام شاه شدن، اگر چه تو باشی \n",
      " به جرم بندگی، غلام شاه شدن \n",
      " چو شاه، غلام توست، غلام اوست \n",
      " به هر کسی که هست غلام اوست \n",
      " به هیچ صورت، آن چنان نباشد \n",
      " که در همه عالم، آن چنان نباشد \n",
      " به هر زبان که سخن گوید کسی \n",
      " سخن من شنو، به جای سخن\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78cf07fb64142f11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
